{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modal SNA MAP473D, Ecole Polytechnique, 2022-23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2 -   \n",
    "## Quantiles empiriques,  \n",
    "## M√©thode de Monte Carlo par Cha√Ænes de Markov (MCMC),  \n",
    "## M√©thode de splitting,  \n",
    "## Estimation de densit√©(*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Les fonctions suivantes pourront √™tre utiles dans ce TP (ex√©cuter _?NomDeLaFonction_ pour afficher ce que fait la fonction):\n",
    ">np.linspace, np.arange, np.mean, np.std, np.logical_and plt.step, plt.plot, plt.hist, plt.legend, plt.axhline, plt.axvline, plt.axis, plt.ylim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estimation de quantiles** dont des quantiles extr√™mes, et calcul d'intervalles de confiance pour ces quantiles.\n",
    "Nous verrons plusieurs m√©thodes, qui exploitent diff√©rents niveaux d'informations dont l'utilisateur peut disposer :\n",
    "\n",
    "- Exercice 1 : on est capable de simuler la variable al√©atoire dont on cherche un quantile. On estimera le quantile empirique.  Ce sera donc une m√©thode non param√©trique.\n",
    "- Exercice 2 : on dispose de r√©alisations d'une loi de probabilit√© dont on cherche le quantile, mais qui est inconnue. On commence par poser un mod√®le statistique param√©trique pour apprendre cette loi; le param√®tre qui assure le meilleur ajustement du mod√®le aux donn√©es est inconnu et peut √™tre estim√© √† l'aide des observations. Ce sera une m√©thode param√©trique.\n",
    "\n",
    "Exercice 3 : **Splitting et MCMC**. on met en oeuvre la m√©thode de splitting combin√©e avec du MCMC pour le calcul de probabilit√©s d'√©v√©nements rares. Une des √©tapes de la m√©thode exploite les techniques de calcul de quantiles empiriques vues pr√©c√©demment.\n",
    "\n",
    "Exercice 4 : **Estimation de densit√©s**. C'est un exercice en option _pour aller plus loin_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Histogramme.** L'histogramme est un estimateur d'une densit√© dont on dispose des r√©alisations i.i.d. $ùëå_1, \\cdots, ùëå_n$. Pour repr√©senter l'histogramme d'un √©chantillon de $n$ v.a., on pourra choisir environ \n",
    "$$ \n",
    "\\frac{2}{7}  \\frac{n^{1/3} L_n}{\\hat{\\sigma}_n}\n",
    "$$ \n",
    "subdivisions, o√π  $\\hat{\\sigma}_n$ est l'√©cart-type empirique de l'√©chantillon et $L_n$ est la longueur de l'intervalle sur lequel s'√©tale l'√©chantillon (voir Exercice 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as sps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Exercice 1. Th√©or√®me de Glivenko-Cantelli et quantiles empiriques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\R}{\\mathbb{R}}$\n",
    "$\\newcommand{\\VR}{\\operatorname{VaR}}$\n",
    "$\\newcommand{\\eqdef}{:=}$\n",
    "$\\newcommand{\\rmd}{\\mathrm{d}}$\n",
    "<span style=\"color:blue\">D√©finition de la fonction Quantile $Q$.</span> Soit $f$ une densit√© par rapport √† la mesure de Lebesgue sur $\\mathbb{R}$. $f$ est suppos√©e continue et strictement positive sur un intervalle $I$ (et nulle en dehors de $I$). \n",
    "La fonction de r√©partition associ√©e, not√©e $F$ est\n",
    "$$\n",
    "F :\\mathbb{R} \\to [0,1], \\qquad \\qquad  F(x) :=  \\int_{-\\infty}^x f(u) \\mathrm{d} u, \\qquad x \\in \\mathbb{R}.\n",
    "$$\n",
    "\n",
    "Les hypoth√®ses sur $f$ entrainent que $F$ est continue et strictement croissante sur $I$; on d√©finit la fonction  quantile $Q : [0,1] \\to \\mathbb{R} \\cup \\{\\pm \\infty\\}$ par\n",
    "$$\n",
    "Q(0) := \\inf I, \\qquad  Q(u) := F^{-1}(u) \\ \\textrm{pour tout $u \\in (0,1)$}, \\qquad  Q(1):=\\sup I.\n",
    "$$\n",
    "\n",
    "\n",
    ">Entre autre en finance, on consid√®re souvent la fonction $\\operatorname{VaR}$ (pour *Value at Risk*) d√©finie par\n",
    "$$\n",
    "\\operatorname{VaR}(\\alpha) := Q(1-\\alpha) \\qquad\n",
    "\\quad  0<\\alpha<1,\n",
    "$$\n",
    ">o√π les valeurs consid√©r√©es de $\\alpha$ sont typiquement proches de z√©ro. Cette fonction est utilis√©e pour mesurer le risque : si  les pertes sont mod√©lis√©es commes des v.a. de densit√© $f$, $\\operatorname{VaR}(0.01)$ repr√©sente la valeur des pertes qui n'est d√©pass√©e que dans $1 \\%$ des cas.}\n",
    "\n",
    "\n",
    "\n",
    "Le but de cette partie est d'estimer la fonction $Q$, √† partir de $n$ donn√©es $(x_1, \\ldots, x_n)$ que l'on mod√©lise comme la r√©alisation de $(X_1, \\ldots, X_n)$ o√π les v.a. $X_i$ sont i.i.d. de loi $f$. \n",
    "> Dans \"la vraie vie\", les mesures $x_1, \\ldots, x_n$ peuvent √™tre obtenues √† l'aide de simulations (typiquement lorsque l'on veut calculer la fonction $\\operatorname{VaR}$ pour une loi $f$ sp√©cifi√©e), ou √™tre des observations historiques (par exemple, lorsque l'on veut calculer la fonction $\\operatorname{VaR}$ associ√©e √† une loi de perte dont on n'observe que des r√©alisations).\n",
    "\n",
    "Etant donn√©es les v.a. $X_1, \\cdots, X_n$, d√©finissons la fonction de r√©partition empirique sur $\\mathbb{R}$ \n",
    "$$\n",
    "F_n(x) := \\frac 1 n \\sum_{i=1}^n 1_{X_i\\leq x}, \\qquad  x \\in \\mathbb{R};\n",
    "$$\n",
    "et les statistiques d'ordre associ√©es $(X_{(i,n)})_{1\\leq i\\leq n}$ : \n",
    "$$\n",
    "X_{(1,n)} \\leq X_{(2,n)} \\leq \\cdots \\leq X_{(i,n)} \\leq \\cdots \\leq X_{(n,n)}.\n",
    "$$\n",
    "√Ä noter que ces in√©galit√©s sont strictes avec probabilit√© $1$ puisque les v.a. sont i.i.d. sous une loi √† densit√©. \n",
    "\n",
    "\n",
    "On consid√®rera successivement le cas o√π $f$  est la densit√© d'une loi\n",
    "- **gaussienne standard**. *Indications : On pourra utiliser la fonction `randn` de `numpy.random` pour  les simuler, et les fonctions `norm.cdf` et `norm.ppf` de `scipy.stats` pour obtenir les valeurs exactes de $F$ et $Q$.  \n",
    "- **loi gamma**. *Indications : On pourra utiliser les fonctions `numpy.random.gamma` et `scipy.stats.gamma` en choisissant leurs param√®tres `shape` et `scale`*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Question 1.1 (th√©orique).</span>   Pour tout $x \\in \\mathbb{R}$, exprimer $F_n(x)$ √† l'aide de $x$ et des statistiques d'ordre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Question 1.2.</span> Le th√©or√®me de Glivenko-Cantelli affirme que presque-s√ªrement, $\\lim_n \\sup_{x \\in \\mathbb{R}} \\big|F_n(x)-F(x) \\big| =0$. Illustrer graphiquement ce r√©sultat dans les deux cas : l'√©chantillon $(X_1, \\cdots, X_n)$ est i.i.d. de loi gaussienne standard, puis  il est i.i.d. de loi gamma. \n",
    "\n",
    "> En python, `X.sort` et `np.sort(X)`\n",
    "\n",
    "> Plusieurs type d'illustration sont possibles. Un choix simple est de superposer l'affichage de $F$ et d'une r√©alisation de $F_n$ pour un certain $n$ fix√©. Cela permet d'appr√©cier visuellement la proximit√© de $F$ et $F_n$ lorsqu'on augmente la valeur de $n$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1897032569.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [1]\u001b[0;36m\u001b[0m\n\u001b[0;31m    n =  ######## A completer ########\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print(\"Question 1.2 Cas Gaussien\")\n",
    "\n",
    "## nombre de simulations\n",
    "n =  ######## A completer ######## \n",
    "\n",
    "## Gaussiennes centrees reduites\n",
    "X = ######## A completer ######## \n",
    "\n",
    "plt.figure(1)\n",
    "# Fct de repartition theorique\n",
    "x = np.linspace(min(X), max(X), 100)\n",
    "F_x = ######## A completer ######## \n",
    "plt.plot(x, F_x, \"r\", linewidth=1.0, label=\"Fct de rep gaussienne\")\n",
    "plt.title(\"Fonctions de repartition th√©orique et empirique, n=%1.0f\" %n)\n",
    "\n",
    "# Fct de repartition empirique\n",
    "F_x_n = ######## A completer ######## \n",
    "\n",
    "## Pensez √† utiliser la fonction plt.step pour l'affichage de F_x_n\n",
    "\n",
    "# On choisit la position de la legende\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Question 1.2 Cas Gamma\")\n",
    "\n",
    "## Nombre de simulations\n",
    "n = ######## A completer ######## \n",
    "## Parametres de la loi Gamma\n",
    "shape=2\n",
    "scale=3\n",
    "\n",
    "######## A completer ######## \n",
    "\n",
    "# Maintenant, on fait apparaitre la legende en dehors du graphique\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=2, fancybox=True, shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">D√©finition de la fonction Quantile empirique $Q_n$.</span>  √Ä la fonction de r√©partition empirique $F_n$, on associe la fonction _quantile empirique_ $Q_n$ d√©finie  sur $]0,1[$ par $$ Q_n(u) := \\inf\\{x\\in \\mathbb{R} : F_n(x) \\geq u \\}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Question 1.3. (th√©orique).</span> Soit $u \\in (0,1)$. Montrer que $$Q_{n}(u) = X_{(\\lceil nu \\rceil,n)},$$ o√π $\\lceil y\\rceil$ d√©signe la partie enti√®re sup√©rieure d'un r√©el $y$.\n",
    "> En python, la partie enti√®re sup√©rieure s'obtient par `numpy.ceil(y)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Question 1.4.</span> Montrer que  presque-s√ªrement, pour  tout $u \\in ]0,1[$, $\\lim_n Q_n(u) = Q(u)$.\n",
    "\n",
    "Illustrer graphiquement cette convergence presque-s√ªre. On pourra comparer la suite des quantiles empiriques √† la valeur exacte $Q(u)$, calculable pour les choix de densit√©s $f$ consid√©r√©s ici √† l'aide des fonctions de `scipy.stats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1870427307.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [5]\u001b[0;36m\u001b[0m\n\u001b[0;31m    Q_u = ????\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print(\"Question 1.4 cas Gaussien \\n\")\n",
    "\n",
    "##nombre de simulations\n",
    "n = 5000\n",
    "\n",
    "#Vraie valeur du quantile \n",
    "u = 0.99\n",
    "Q_u = ????\n",
    "\n",
    "X = ????\n",
    "\n",
    "# Evolution du quantile empirique: A compl√©ter\n",
    "\n",
    "print(\"Question 1.4 cas Gamma \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">TCL pour l'estimateur $Q_n(u)$.</span> On peut d√©montrer (voir transparents de l'amphi) que pour tout $u \\in \\, ]0,1[$,\n",
    "\n",
    "$$\n",
    "\\sqrt{n}\\frac{f(Q(u))}{\\sqrt{u(1-u)}}\\left(Q_{n}(u)-Q(u)\\right) \\quad  \\stackrel{\\text{loi}}{\\longrightarrow} \\quad  \\mathcal{N}(0,1). \\qquad \\qquad (1)\n",
    "$$\n",
    "\n",
    "Cela signifie que, lorsque $n$ est grand, les fluctuations de  $Q_n(u)$ autour de  $Q(u)$ se comportent en loi comme une gaussienne centr√©e, d'√©cart-type d'ordre $\\frac{ \\sqrt{u(1-u)}}{\\sqrt{n} \\, f(Q(u))}$.  Ce r√©sultat peut en particulier servir √† donner une estimation par intervalles de confiance de la quantit√© $Q(u)$ inconnue.  En pratique, n√©anmoins, on est confront√© √† deux difficult√©s dans l'√©valuation de l'√©cart-type de l'erreur normalis√©e :  \n",
    "- le fait que $Q(u)$ n'est pas connu. Le lemme de Slutsky justifie n√©anmoins de remplacer $Q(u)$ par l'estimateur $Q_n(u)$.  \n",
    "- le fait que la densit√© $f$ n'est pas connue.\n",
    "\n",
    "<span style=\"color:blue\">Question 1.5. Intervalle de confiance, $f$ connue</span>  Dans cette question, on suppose que l'expression de la densit√© $f$ est connue (mais $Q(u)$ n'est pas connue).\n",
    "\n",
    "1. Soit $u \\in ]0,1[$. D√©duire de la convergence en loi (1) l'expression d'un intervalle de confiance asymptotique de probabilit√© de couverture $95 \\%$ pour la quantit√© $Q(u)$. \n",
    "\n",
    "2. Dans le cas o√π $f$ est la densit√© d'une loi gaussienne standard, puis le cas o√π c'est une loi gamma : calculer cet intervalle de confiance √† partir de $n$ r√©alisations de v.a. $X_1, \\cdots, X_n$ de loi $f$, et illustrer la convergence en loi (1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"**Question 1.5 cas Gaussien** \\n\")\n",
    "\n",
    "##nombre de simulations\n",
    "n = 5000\n",
    "\n",
    "#Vraie valeur du quantile \n",
    "u = 0.99\n",
    "Q_u = sps.norm.ppf(u)\n",
    "\n",
    "X = np.random.randn(n)\n",
    "\n",
    "##################################################\n",
    "# Compl√©ter avec:\n",
    "# + le calcul et affichage de l'IC asymptotique\n",
    "# + l'histogramme de l'erreur normalisee\n",
    "##################################################\n",
    "\n",
    "\n",
    "print(\"**Question 1.5 cas Gamma** \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "$\\newcommand{\\Var}{\\operatorname{Var}}$\n",
    "<span style=\"color:blue\">Question 1.6. Intervalles de confiance, $f$ inconnue.</span> \n",
    "Dans les cas o√π $f$ n'est pas connue, on peut proc√©der √† une estimation de la variance asymptotique de l'erreur renormalis√©e apparaissant dans le TCL (voir (1)) afin de pouvoir fournir un intervalle de confiance. Cela est possible, quitte √† simuler plusieurs fois l'estimateur $Q_n(u)$.\n",
    "\n",
    "Nous allons voir une technique alternative, qui utilise un seul jeu de $n$ simulations (le m√™me que celui utilis√© pour le calcul de $Q_n(u)$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Montrer que  pour tout $u \\in ]0,1[$, \n",
    "$$ \\sqrt{n} (F_n(Q(u))- F(Q(u)))  = \\sqrt{n} (F_n(Q(u))- u)  \\stackrel{loi}{\\longrightarrow}  \\mathcal{N}(0,u(1-u)).$$\n",
    "\n",
    "\n",
    "2. Soit $u \\in ]0,1[$; on pose\n",
    "$$  u^-_n := u  - 1.96  \\,  \\frac{\\sqrt{u (1-u)}}{\\sqrt{n}}, \\qquad u^+_n := u + 1.96 \\,  \\frac{\\sqrt{u (1-u)}}{\\sqrt{n}}.$$ \n",
    "Montrer que $[Q_n(u_n^-),Q_n(u_n^+)[$ est un intervalle de confiance asymptotique de probabilit√© de couverture  $95\\%$ pour $Q(u)$.\n",
    "\n",
    "\n",
    "3. Illustrer num√©riquement ce calcul d'intervalle de confiance pour des valeurs de $u=1-\\alpha$ allant de $\\alpha=10^{-2}$ √† $\\alpha=10^{-5}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Question 1.6 Cas Gaussien *** \n",
      "\n",
      "***Question 1.6 cas Gamma  ***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"*** Question 1.6 Cas Gaussien *** \\n\")\n",
    "\n",
    "\n",
    "print(\"***Question 1.6 cas Gamma  ***\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Esp√©rance conditionnelle de queue.</span>  Une fois le quantile estim√©, il est parfois int√©ressant d'estimer l'*Expected Shortfall*, qui se d√©finit comme √©tant l'esp√©rance conditionnelle de queue $$E_{1-u}:= \\mathbb{E}[X_1\\,|\\, X_1> Q(u)], \\qquad X_1 \\sim f. $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Question 1.7.</span>  Dans le cas o√π $f$ est la loi gaussienne centr√©e r√©duite, puis dans le cas o√π $f$ est la loi gamma : donner un intervalle de confiance asymptotique de probabilit√© de couverture  $95\\%$ pour l'esp√©rance conditionnelle de queue et l'illustrer num√©riquement.\n",
    "\n",
    "> Dans cette question, on pourra se contenter d'estimer $Q(u)$ par le quantile empirique, et ensuite utiliser le fait que les variables al√©atoires $\\{X_i: X_i > X_{(\\lceil nu\\rceil,n)} \\}$ sont approximativement i.i.d. et distribu√©es selon la loi de $X$ sachant $X> Q(u)$. Plus pr√©cis√©ment, on pourra utiliser le fait que les variables al√©atoires $\\{X_i: X_i > X_{(\\lceil n u\\rceil,n)} \\}$ satisfont √† un th√©or√®me central limite: le Th√©or√®me 4.1 (iii) page 80 [dans ce document](https://tel.archives-ouvertes.fr/tel-00743159/document) fournit des √©l√©ments de th√©orie.\n",
    "\n",
    "Dans le cas de la loi gaussienne centr√©e r√©duite, on pourra comparer avec la valeur exacte $ \\quad  (1-u)^{-1} \\, f(\\Phi^{-1}(u)) \\quad $\n",
    "o√π $\\Phi$ d√©signe la fonction de r√©partition de la loi gaussienne centr√©e r√©duite. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*** Question 1.7 : cas Gaussien*** \\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print (\"*** Question 1.7 : cas Gamma*** \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## Exercice 2. Estimation param√©trique\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cet exercice, on dispose de  donn√©es $x_{1}, \\ldots,x_{n}$ mod√©lis√©es comme la r√©alisation d'un vecteur al√©atoire $(X_{1}, \\ldots,X_{n})$ que l'on suppose √™tre un $n$-√©chantillon d'une loi _inconnue_.  On d√©finit un mod√®le statistique param√©trique : on va chercher la loi qui, dans une famille de lois param√©trique donn√©e $\\{f_\\theta, \\theta \\in \\mathbb{R}^d \\}$, s'ajuste au mieux aux donn√©es. Dans la suite, on prend pour famille de lois:\n",
    "\n",
    "$$(\\mathbb{R}, \\mathcal{B}(\\mathbb{R}), \\{ \\mathcal{N}(0,\\sigma^2), \\sigma^2 > 0 \\}). $$\n",
    "\n",
    "On rappelle que la variance d'une loi $\\mathcal{N}(0, \\sigma^2)$ est $\\sigma^{2}$ et que son moment d'ordre $4$ vaut $3 \\sigma^4$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Question 2.1. Intervalles de confiance pour $\\sigma$.</span> Nous allons d'estimer $\\sigma$ √† partir de l'observation de $X_1, \\ldots, X_n$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a)  Utiliser la statistique $M_n : = n^{-1}\\sum_{i=1}^n X_i^2$.  Sous $\\mathbb{P}_\\sigma$, quelle est la loi de $n M_n/\\sigma^2$ ? En d√©duire un intervalle de confiance non asympototique de probabilit√© de couverture $1-\\alpha$.  \n",
    "√âcrire un code donnant un intervalle de confiance (non asymptotique) de probabilit√© de couverture  $95\\%$   pour $\\sigma$. \n",
    "> Indication : on pourra utiliser la loi du $\\chi^{2}$ et la fonction `sps.chi2.ppf`).\n",
    "\n",
    "Application num√©rique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"*** Question 2.1 *** \\n\")\n",
    "\n",
    "#####################\n",
    "## IC non asymptotique\n",
    "#####################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) D√©montrer que  $\\sqrt{n} \\left(  \\sqrt{M_n }-\\sigma \\right)  \\stackrel{loi}{ \\rightarrow}  \\mathcal{N}(0,\\sigma^{2}/2)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) √âcrire un code donnant un intervalle de confiance asymptotique de probabilit√© de couverture  $95\\%$ pour $\\sigma$ et bas√© sur la statistique $M_n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "## IC asymptotique\n",
    "#####################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Question 2.2. Intervalles de confiance pour $Q(u,\\sigma)$.</span>  Notons $Q(u,\\sigma)$ le quantile en $u$ de la loi $\\mathcal{N}(0,\\sigma^{2})$. On admettra que\n",
    "$$\\sqrt n \\left(Q \\left( u, \\sqrt{M_n} \\right)  - Q(u,\\sigma) \\right)\n",
    " \\stackrel{loi}{\\longrightarrow} \\mathcal{N} \\left(0, \\frac{Q(u,\\sigma)^2}2 \\right).  \\qquad \\qquad (2)\n",
    "$$\n",
    "\n",
    "Cette relation entraine en particulier que $Q(u,\\sqrt{M_n})$ est un estimateur consistant de $Q(u,\\sigma)$.\n",
    "\n",
    "\n",
    "\n",
    "On veut estimer le quantile $Q(u,\\sigma)$ ainsi qu'un intervalle de confiance asymptotique √† $95\\%$ de $Q(u,\\sigma)$. Comparer, pour diff√©rentes valeurs de $n$,  \n",
    "- la valeur exacte du quantile $Q(u,\\sigma)$,  \n",
    "\n",
    "_m√©thode 1_\n",
    "- la valeur obtenue en estimant $\\sigma$ puis en calculant le quantile par `scipy.stats.norm.ppf`, \n",
    "- un IC asymptotique pour $Q(u,\\sigma)$ obtenu en exploitant (2). \n",
    "\n",
    "_m√©thode 2_\n",
    "- l'estimateur de quantile empirique (voir exercice 1)\n",
    "- l'IC asymptotique obtenu en utilisant le TCL (1) de l'exercice 1.  \n",
    "\n",
    "_m√©thode 3_\n",
    "- l'IC asymptotique obtenu en utilisant la question 1.6 de l'Exercice 1.\n",
    "\n",
    "\n",
    "On pourra faire cette exp√©rience notamment pour des valeurs de $u$ proches de $1$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Question 2.2 *** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"*** Question 2.2 *** \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<span style=\"color:blue\">Question 2.3. (facultative).</span> D√©montrer la convergence en loi (2) apparaissant dans la Question 2.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## Exercice 3. Th√©or√®me ergodique et m√©thode de splitting\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Th√©or√®me ergodique pour le processus $\\operatorname{AR}(1)$ stationnaire ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un processus $\\operatorname{AR}(1)$ gaussien stationnaire est d√©fini par r√©currence comme suit (pour simplifier, on se place en dimension $1$).  On fixe $\\rho\\in ]-1,1[$ et on pose pour $i\\ge 1$,\n",
    "\n",
    "$$\n",
    "X_i := \\rho X_{i-1}+\\sqrt{1-\\rho^2}  Y_i, \\qquad \\qquad  X_0 = Y_0 \\qquad (3)\n",
    "$$\n",
    "\n",
    "o√π $(Y_i)_{i\\ge 0}$ est une suite de variables al√©atoires i.i.d. de loi \n",
    "$\\mathcal{N}(0, 1)$, ind√©pendante de $X_0$.\n",
    "C'est donc un processus qui se renouvelle d'un instant √† l'autre en gardant une part de son ancienne valeur ($\\rho X_{i-1}$) et en ajoutant une part d'_innovation_ $\\sqrt{1-\\rho^2} Y_i$.\n",
    "\n",
    "De fa√ßon √©quivalente, nous avons \n",
    "$$\n",
    "X_i\\;=\\;\\rho^i X_0+\\sqrt{1-\\rho^2}\\sum_{j=1}^{i}\\rho^{i-j}Y_{j}. \\qquad \\qquad \\qquad (4)\n",
    "$$\n",
    "\n",
    "> L'expression de $X_i$ dans l'√©quation (3) se pr√™te naturellement √† une impl√©mentation avec une boucle `for`.  Cette expression exprime clairement la propri√©t√© markovienne du processus $(X_i)_i$.  \n",
    "L'√©quation (4) permet d'effectuer des calculs plus rapides que (3) en utilisant la programmation matricielle de `numpy` plut√¥t que des boucles, mais, d'un autre cot√©, elle peut mener √† des probl√®mes de pr√©cision lorsque $i\\gg 1$, puisqu'elle am√®ne √† calculer des expressions du type $\\rho^{\\textrm{(tr√®s grand nombre)}}$.\n",
    "Nous d√©conseillons donc l'usage de l'expression (4) en pratique. Sous l'angle de vue probabiliste, l'avantage de l'equation (4) est de permettre un calcul rapide de la loi de $X_i$ en tant que combinaison lin√©aire de v.a. gaussiennnes i.i.d. On peut v√©rifier que pour tout $i \\geq 0$, $X_i \\sim  \\pi_\\star := \\mathcal{N}(0,1)$.\n",
    "\n",
    "<span style=\"color:blue\">Th√©or√®me ergodique.</span>  Il affirme que \n",
    "pour tout  $B\\subset \\mathbb{R}$ mesurable, presque s√ªrement, \n",
    "$$\\frac{1}{n}\\sum_{i=1}^n 1_{X_i\\in B} \\quad \\mathop{\\longrightarrow}_{n \\to \\infty}  \\quad \\mathbb{P}(Z\\in B), \\qquad \\textrm{o√π } Z \\sim \\mathcal{N}(0,1) . \\qquad \\qquad \\qquad (5)$$\n",
    "\n",
    "> Nous avons vu que la cha√Æne de Markov √©tait stationnaire (les v.a. $X_i$ ont m√™me loi) et de loi stationnaire $\\pi_\\star$.  C'est cette loi stationnaire qui appara√Æt comme loi limite dans le th√©or√®me ergodique.\n",
    "\n",
    "Concr√®tement, pour $n\\gg 1$, l'histogramme de $X_1, \\ldots, X_n$ est proche de la densit√© de $\\mathcal{N}(0, 1)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Question 3.1.</span> Illustrer la proximit√© entre l'histogramme de l'√©chantillon $(X_i)_{1 \\le i \\le n}$ et la loi $\\mathcal{N}(0,1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Question 3.1 ####\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Th√©or√®me ergodique et m√©thode de splitting ####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si l'on modifie la dynamique du processus $X$ dans (3) en conditionnant √† l'appartenance √† un ensemble mesurable $A\\subset \\mathbb{R}$,  la convergence (5) reste valable (au sens conditionnel). Soit $A\\subset \\mathbb{R}$  un ensemble mesurable de mesure de Lebesgue strictement positive. \n",
    "\n",
    "Soit $\\tilde X_0$ une v.a. de  loi gaussienne centr√©e r√©duite conditionn√©e √† appartenir √† $A$. Etant donn√©es une suite de v.a. $(Y_i)_i$ i.i.d. de loi $\\mathcal{N}(0,1)$ et ind√©pendantes de $\\tilde X_0$, on d√©finit pour pour tout $i \\geq 1$,\n",
    "$$\n",
    " \\tilde X_{i+1/2}:=  \\rho \\tilde X_{i-1} +\\sqrt{1-\\rho^2} Y_i, \\qquad Y_i \\sim \\mathcal{N}(0,1), \n",
    "$$\n",
    "puis \n",
    "\\begin{equation*}\\label{eqAR(1)2} \\tilde X_{i+1} := \\begin{cases} \\tilde X_{i+1/2} & \\textrm{ si $\\tilde X_{i+1/2}\\in A$,}\\\\ \\tilde X_{i} &\\textrm{ sinon,}\\end{cases} \\qquad \\qquad (6)\n",
    "\\end{equation*}\n",
    "On a  \n",
    "- pour tout $i \\geq 0$, $\\tilde X_i$ suit la loi gaussienne centr√©e r√©duite conditionn√©e √† appartenir √† $A$,  \n",
    "- le th√©or√®me ergodique reste valable: pour tout $B\\subset \\mathbb{R}$  mesurable,  presque s√ªrement\n",
    "\\begin{equation*}\\label{eqAR(1)TE2}\n",
    "\\frac{1}{n}\\sum_{i=1}^n 1_{\\tilde X_i \\in B}  \\quad \\mathop{\\longrightarrow}_{n \\rightarrow \\infty} \\quad \\mathbb{P}(Z\\in B \\,|\\, Z\\in A)\\qquad \\qquad   Z\\sim \\mathcal{N}(0, 1) \\qquad (7)\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Question 3.2.</span>  Prendre $A := [a,+\\infty[$.\n",
    "Illustrer la proximit√© entre l'histogramme de l'√©chantillon $( \\tilde X_i)_{1 \\le i \\le n}$ et la loi conditionnelle de $Z$ sachant $\\{Z \\in A\\}$, o√π $Z \\sim \\mathcal{N}(0,1)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Question 3.2 ####\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">M√©thode de splitting.</span> Pour calculer $\\mathbb{P}(Z\\in A)$, l'id√©e du _splitting_ est  d'utiliser une suite d√©croissante de \"cibles\"\n",
    "$\\mathbb{R}=A_0\\supset A_1\\supset\\cdots\\supset A_k=A$\n",
    "et de calculer $\\mathbb{P}(Z\\in A)$ avec la formule \n",
    "\n",
    "\\begin{equation*} \n",
    "\\mathbb{P}(Z\\in A)=\\prod_{\\ell=1}^k \\mathbb{P}(Z\\in A_{\\ell}\\,|\\, Z\\in A_{\\ell-1}) \\qquad \\qquad (8)\n",
    "\\end{equation*}\n",
    "\n",
    "o√π chaque probabilit√© conditionnelle est approch√©e via la limite (7), √† l'aide de v.a. $(\\tilde X_i^{(\\ell)})_i$  simul√©es selon l'algorithme (6) appliqu√© avec $A \\leftarrow A_{\\ell-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Question 3.3.</span>  Illustrer la m√©thode de splitting pour le calcul de $\\mathbb{P}(Z>a)$ pour $Z\\sim \\mathcal{N}(0,1)$, $a=4$ et $\\rho = 0.6$.\n",
    "\n",
    "La valeur de cette probabilit√© est connue et accessible via les fonctions `scipy.stats.norm.pdf` ou `scipy.stats.norm.sf`. On souhaite ici tester les performances d'un algorithme d'estimation bas√© sur la repr√©sentation (8) et sur le r√©sultat de convergence (7), dans un cas simple.\n",
    "\n",
    "Plus pr√©cis√©ment, on pourra tester l'algorithme suivant :  \n",
    "- Etape 1: on id√©ntifie des ensembles $A_l$ raisonnables. En utilisant un nombre $n$ de tirages pas tr√®s √©lev√© ($n=500$ ou $n=1000$ par exemple), on estime, en se basant sur la convergence (7), des valeurs\n",
    "$$\n",
    "-\\infty=a_0<a_1<\\cdots <a_k < a \\leq a_{k+1}\n",
    "$$\n",
    "telles que pour tout $\\ell$,\n",
    "$$\n",
    "\\mathbb{P}(Z>a_\\ell\\,|\\,Z>a_{\\ell-1})\n",
    "\\simeq 0.1.\n",
    "$$\n",
    "\n",
    "> Indication : penser au fait que le calcul de $a_\\ell$ (une fois que $a_{\\ell-1}$ est connu) revient √† l'estimation d'un quantile! Pour cela, on pourra admettre que les th√©or√®mes limites de l'Exercice 1 restent vrais pour l'√©chantillon $(\\tilde X_i^{(\\ell)})_i$.\n",
    "\n",
    "\n",
    "- Etape2: on estime alors chacune des probabilit√©s conditionnelles $\\mathbb{P}(Z>a_\\ell\\,|\\,Z>a_{\\ell-1})$ via une m√©thode encore fond√©e sur (7), en utilisant maintenant un nombre de tirages plus √©lev√© (par exemple de l'ordre de $n=5.10^4$). On estime aussi, pour la derni√®re probabilit√© : $\\mathbb{P}(Z>a \\,|\\, Z > a_k)$. \n",
    "\n",
    "> Attention, en toute rigueur, $k$ est un nombre al√©atoire; ce que les notations utilis√©es dans cette section ne refl√®tent pas, pour simplifier l'expos√©.*\n",
    "\n",
    "\n",
    "3. On en d√©duit  $\\mathbb{P}(Z>a)$ via la formule (8), et on compare le r√©sultat obtenu √† la valeur approch√©e obtenue par un Monte-Carlo simple r√©alis√© avec autant de simulations (c√†d avec $n \\, k$ simulations), ainsi qu'√† la valeur exacte donn√©e par la fonction `scipy.stats.norm.sf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Question 3.3 ####\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## Exercice 4. Estimation de la densit√©\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cet exercice, on consid√®re une suite $(X_i)_{i\\ge 1}$ de al√©atoires i.i.d. dont on suppose qu'elles ont une densit√© $f$ sur $\\R$. Afin d'estimer $f$, pour chaque valeur de $n$, on va construire, √† partir des observations $X_1, \\ldots, X_n$, une densit√© $f_n$.\n",
    "Cette densit√© pourra, selon la strat√©gie choisie, √™tre construite via diff√©rents proc√©d√©s, et on verra dans quelle mesure, pour $x\\in \\R$,\n",
    "$$\n",
    "f_n(x)\\underset{n\\to\\infty}{\\longrightarrow} f(x).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Histogramme ####\n",
    "\n",
    "Pour chaque valeur de $n$, on fixe une subdivision $a_{n,0}<a_{n,1}<\\cdots$ de $\\R$, et $f_n$ est la fonction constante sur chaque intervalle $]a_{n,k-1}, a_{n,k}]$ telle que  pour tout $k$,\n",
    "\n",
    "$$\\int^{a_{n,k}}_{a_{n,k-1}}f_n(x)\\textrm{d} x\n",
    "=\n",
    "\\frac 1 n \n",
    "\\textrm{Card}\\{i\\in \\{1,¬†\\ldots, n\\}: a_{n,k-1} < X_i\\le a_{n,k}\\}\n",
    "= F_n(a_{n,k}) - F_n(a_{n,k-1}).\n",
    "$$\n",
    "\n",
    "Rappelons que dans `matplotlib.pylot`, la fonction `hist` trace un histogramme de la mani√®re suivante: pour `V` un vecteur de donn√©es, on peut tracer  l'histogramme de `V` selon deux proc√©d√©s: \n",
    "\n",
    "1. Pour tout entier `n`, la commande `hist(V, bins=n)` (ou simplement `hist(V, n)`) trace l'histogramme associ√© √† la subdivision r√©guli√®re √† `n` intervalles, allant du plus petit √©l√©ment de `V` au plus grand.\n",
    "\n",
    "2. On peut aussi prescrire la subdivision utilis√©e dans le tra√ßage de l'histogramme en rempla√ßant l'argument `n` par une subdivision (i.e. un vecteur de r√©els croissants sous la forme d'un \\src{list} ou d'un `numpy.array`). Dans ce cas, les valeurs de `V` qui sont hors des bornes de la subdivision ne sont pas prises en compte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Fen√™tres glissantes ####\n",
    "Pour chaque valeur de $n$, on fixe $h_n>0$ (la _largeur de fen√™tre_) et on d√©finit la densit√© $f_n$ par la formule :\n",
    " \n",
    "$$\\label{def_fenetre_gli}\\forall x\\in \\R,¬†\\qquad f_n(x) := \n",
    "\\frac 1 {n \\, h_n}\n",
    "\\textrm{Card}\\Big\\{i\\in \\{1,¬†\\ldots, n\\}: x-\\frac{h_n}{2}< X_i\\le x+\\frac{h_n}{2}\\Big\\}. \\qquad \\qquad (9)\n",
    " $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Comment choisir la largeur des colonnes de l'histogramme ou des fen√™tres glissantes ? ####\n",
    "\n",
    "On unifie les approches des deux paragraphes pr√©c√©dents en notant $f_n$ la densit√© empirique construite soit via l'approche \"histogramme\", soit via l'approche \"fen√™tres glissantes\".\n",
    "\n",
    "Il est facile d'imaginer ce qu'il se produit si l'histogramme a trop peu de colonnes ou si les fen√™tres glissantes sont trop larges: l'approximation de la densit√© qui en r√©sulte est tr√®s grossi√®re. \n",
    "\n",
    "N√©anmoins, augmenter le nombre de colonnes excessivement ou affiner les fen√™tres glissantes √† l'extr√™me ne produit pas non plus une bonne approximation de la densit√©: cela augmente la variance dans l'estimation de $f$ dans chaque colonne (ou fen√™tre)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.1 ####\n",
    "\n",
    "$\\blacktriangle$ Illustrer les deux assertions pr√©c√©dentes (pour l'approche  _histogramme_ uniquement) avec une simulation : on tire $n$ variables al√©atoires i.i.d. ayant une densit√© $f$ (par exemple des gaussiennes standard) et on compare la densit√© $f$ √† son approximation via un histogramme en choisissant soit tr√®s peu, soit beaucoup  de colonnes.\n",
    "\n",
    "$\\blacktriangle$ La question du choix optimal pour la largeur des colonnes (ou des fen√™tres) est d√©licate, notamment car sa r√©ponse d√©pend fortement de l'information disponible quant √† la densit√© $f$ √† approcher.\n",
    "Dans l'article [Scott 79](https://www.jstor.org/stable/2335182?seq=1#metadata_info_tab_contents), il est sugg√©r√© d'utiliser une largeur de colonne √©gale √† $a \\, \\sigma_n  \\, n^{-1/3}$, o√π $a=3.49$, $\\sigma_n$ est l'√©cart-type  de l'√©chantillon et $n$ est la taille de l'√©chantillon  (dans le cas de la densit√© gaussienne, ce choix minimise une erreur quadratique). Cela signifie que si notre √©chantillon s'√©tale sur un intervalle de longueur $L$, notre histogramme devra avoir $N\\approx \\frac{n^{1/3}L}{a \\, \\sigma_n}$ colonnes. Illustrer cette affirmation avec des simulations  de variables al√©atoires i.i.d. suivant diverses lois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 4.1 ###\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
